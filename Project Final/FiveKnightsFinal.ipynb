{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f9181df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tkinter import *\n",
    "from PIL import Image, ImageTk\n",
    "# import time\n",
    "# import argparse\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b678df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_image_path(file_path):\n",
    "    file_type = \".jpg\"\n",
    "    image_paths = []\n",
    "\n",
    "    for subs, dirs, files in os.walk(file_path):\n",
    "        for file in files:\n",
    "            path = subs + file\n",
    "            image_paths.append(path)\n",
    "    image_paths.sort()\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf3a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image():\n",
    "    global sorted_images, img_cur_idx\n",
    "    img = cv2.imread(sorted_images[img_cur_idx])\n",
    "    img_cur_idx += 1\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15bb08e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_inside(o,i):\n",
    "    ox,oy,ow,oh = o\n",
    "    ix,iy,iw,ih = i\n",
    "    return ox>ix and oy>iy and ox+ow<ix+iw and oy+oh<iy+ih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f988ff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_person(image,person, color):\n",
    "    x,y,w,h = person\n",
    "    cv2.rectangle(image, (x,y), (x+w, y+h),color,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc1a621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Hog to find the pedestrians list & return the list\n",
    "def findlist(img):\n",
    "    global hog\n",
    "    img_gau = cv2.GaussianBlur(img, (9, 9), 0)\n",
    "    grey = cv2.cvtColor(img_gau, cv2.COLOR_RGB2GRAY)\n",
    "    found, w = hog.detectMultiScale(grey, winStride=(10,10))\n",
    "    found_list = []\n",
    "    for ri, r in enumerate(found):\n",
    "        flag = 0\n",
    "        for qi, q in enumerate(found):\n",
    "            if ri != qi and is_inside(r,q):\n",
    "                flag = 1\n",
    "        if flag == 0:\n",
    "            found_list.append(r)\n",
    "    return found_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9928b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the starter mouse touch point\n",
    "def get_mouse_posn(event):\n",
    "    global topy, topx\n",
    "    \n",
    "    topx, topy = event.x, event.y\n",
    "    \n",
    "# Get the final mouse touch point & update select status\n",
    "def update_sel_rect(event):\n",
    "    global rect_id\n",
    "    global topy, topx, botx, boty\n",
    "    global select\n",
    "\n",
    "    botx, boty = event.x, event.y\n",
    "    select = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99c4d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the iou score and return it\n",
    "def cal_bounding_boxes_iou(b1, b2):\n",
    "    x1,y1,w1,h1 = b1\n",
    "    x2,y2,w2,h2 = b2\n",
    "\n",
    "    # determine the coordinates of the intersection rectangle\n",
    "    x_left = max(x1, x2)\n",
    "    y_top = max(y1, y2)\n",
    "    x_right = min(x1+w1, x2+w2)\n",
    "    y_bottom = min(y1+h1, y2+h2)\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0\n",
    "    \n",
    "    # compute the area of the bouding boxes when boxes overlap\n",
    "    b1_area = (w1 * h1)\n",
    "    b2_area = (w2 * h2)\n",
    "    \n",
    "    # compute the area of the intersection between bounding boxes\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    # compute the intersection over union between bounding boxes\n",
    "    iou = intersection_area / float(b1_area + b2_area - intersection_area)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae099d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conver list to string\n",
    "def list_to_str(list):\n",
    "    return ','.join(str(i) for i in list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed1b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find nearest pedestrian and check whether they unique or not\n",
    "def find_nearest(center, pre_center_list):\n",
    "    min_distance = 50\n",
    "    nearest_c = 0\n",
    "\n",
    "    for cc in pre_center_list:\n",
    "        temp_distance = ((center['center'][0] - cc['center'][0]) ** 2 + (center['center'][1] - cc['center'][1]) ** 2) ** 0.5\n",
    "        if temp_distance < min_distance:\n",
    "            min_distance = ((center['center'][0] - cc['center'][0]) ** 2 + (center['center'][1] - cc['center'][1]) ** 2) ** 0.5\n",
    "            nearest_c = cc\n",
    "    return nearest_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4d94173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box(img, found_list):\n",
    "    global pre_center_list, line_list,total_num_ped,total_ped_list,total_ped_dict\n",
    "    curr_center_list = []\n",
    "    pedestrian_number = 0\n",
    "    ped_in_group_count = 0\n",
    "    group_formation_count = 0\n",
    "    group_destruction_count = 0\n",
    "    new_ped_count = 0\n",
    "    for index, person in enumerate(found_list):\n",
    "        x, y, w, h = person\n",
    "        pedestrian_number += 1\n",
    "        center = (int(x), int(y+h))\n",
    "        center_dict = {'center':center}\n",
    "        nn = find_nearest(center_dict, pre_center_list) \n",
    "        person_color = []\n",
    "        if nn == 0:\n",
    "            new_ped_count += 1\n",
    "            rand_color = random.choices(range(256), k=3)\n",
    "            person_color = rand_color\n",
    "            person_dic = {'id': index, 'center': center, 'area': w*h,'color':rand_color,'inGroup': 0, 'inFrame': 1}\n",
    "            curr_center_list.append({'center':center,'color':rand_color})\n",
    "            total_ped_dict[list_to_str(rand_color)] = person_dic\n",
    "            total_num_ped += 1\n",
    "            total_ped_list.append(person_dic)\n",
    "        else:\n",
    "            line_list.append({'color':nn['color'],'line':[nn['center'], center]})\n",
    "            curr_center_list.append({'center':center,'color':nn['color']})\n",
    "            person_color = nn['color']\n",
    "        #### 3.1 & 3.2\n",
    "        dic_key = list_to_str(person_color)\n",
    "        person_dic = total_ped_dict.get(dic_key)\n",
    "        group_flag = 0\n",
    "        for p in found_list:\n",
    "            if(np.array_equal(p,person)):\n",
    "                continue\n",
    "            else:\n",
    "                iou = cal_bounding_boxes_iou(person, p)\n",
    "                if(iou > 0.13):\n",
    "                    if (group_flag == 0):\n",
    "                        if (person_dic['inGroup'] == 0):\n",
    "                            group_formation_count +=1\n",
    "                        person_dic.update({'inGroup': 1})\n",
    "                        total_ped_dict[dic_key] = person_dic\n",
    "                        ped_in_group_count +=1\n",
    "                        group_flag = 1\n",
    "        if (group_flag == 0):\n",
    "            if (person_dic['inGroup'] == 1):\n",
    "                group_destruction_count +=1\n",
    "            person_dic.update({'inGroup': 0})\n",
    "            total_ped_dict[dic_key] = person_dic\n",
    "        ### 3.1 & 3.2\n",
    "        draw_person(img, person,person_color)\n",
    "    #if if_next != 0:\n",
    "    for line in line_list:\n",
    "        exist = 0\n",
    "        #if find_nearest(pre, curr_center_list) == 0:\n",
    "        for curr in curr_center_list:\n",
    "            if line['color'] == curr['color']:\n",
    "                exist = 1\n",
    "        if exist == 1:\n",
    "            cv2.line(img, line['line'][0], line['line'][1], line['color'],thickness=3)\n",
    "    leave_count = 0\n",
    "    for p in pre_center_list:\n",
    "        exist2 = 0\n",
    "        for curr in curr_center_list:\n",
    "            if p['color'] == curr['color']:\n",
    "                exist2 = 1\n",
    "        if exist2 == 0:\n",
    "            leave_count += 1\n",
    "            \n",
    "    pre_center_list = [_ for _ in curr_center_list]\n",
    "    cv2.putText(img, f'The number of pedestrain is {len(curr_center_list)}', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)\n",
    "    cv2.putText(img, f'Total number of pedestrain is {total_num_ped}', (10, 80), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)\n",
    "    cv2.putText(img, f'New pedestrian entering {new_ped_count}', (10,120), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)\n",
    "    cv2.putText(img, f'Num of Pedestrian leaving {leave_count}', (10,150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)\n",
    "    cv2.putText(img, f'Number of pedstrain walk as group: {ped_in_group_count}; walk as alone: {len(found_list)-ped_in_group_count}', (10, 1020), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)\n",
    "    cv2.putText(img, f'Group formation: {group_formation_count} pedestrain(s) join. Group destruction: {group_destruction_count} pedestrain(s) leave.', (10, 1050), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d535c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop all the image from the file path\n",
    "def play_video():\n",
    "    global play_output_images, sorted_images, stop\n",
    "    stop = False\n",
    "    while img_cur_idx < len(sorted_images) and not stop:\n",
    "        image = load_image()\n",
    "        found_list = findlist(image)\n",
    "        new_image = bounding_box(image, found_list)\n",
    "        new_image = cv2.resize(new_image,dsize=(int(org_w/scale_size),int(org_h/scale_size)),fx=1,fy=1,interpolation=cv2.INTER_LINEAR)\n",
    "        play_output_images.append(new_image)\n",
    "        PIL_image = Image.fromarray(new_image)\n",
    "        photo = ImageTk.PhotoImage(PIL_image)\n",
    "        \n",
    "        image_label.configure(image=photo)\n",
    "        image_label.image = photo\n",
    "\n",
    "        my_window.update_idletasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae031808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the bouding box is it contain in the selection area\n",
    "def contains_bounding_box(sel_b, b):\n",
    "    selx, sely, selw, selh = sel_b\n",
    "    x, y, w, h = b\n",
    "    if (selx <= x and sely <= y and (selx+selw) >= (x+w) and (sely+selh) >= (y+h)):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bbddef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check pedestrian is it in the selection area\n",
    "def selected_ped_in_the_box(found_list, select_box):\n",
    "    selected_found_list = []\n",
    "    for p in found_list:\n",
    "        if (contains_bounding_box(select_box, p)):\n",
    "            selected_found_list.append(p)\n",
    "            continue\n",
    "        iou = cal_bounding_boxes_iou(select_box, p)\n",
    "        if(iou > 0.075):\n",
    "            selected_found_list.append(p)\n",
    "    return selected_found_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49de24cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the next image from the file path\n",
    "def next_image():\n",
    "    global topy, topx, botx, boty, next_output_images, select\n",
    "    image = load_image()\n",
    "    found_list = findlist(image)\n",
    "    new_image = bounding_box(image, found_list)\n",
    "    if select is True:\n",
    "        img_selected = cv2.rectangle(image, (topx*scale_size,topy*scale_size), (botx*scale_size, boty*scale_size),(255,255,255),2)\n",
    "        select_box = [topx*scale_size, topy*scale_size, (botx-topx)*scale_size, (boty-topy)*scale_size]\n",
    "        selected_found_list = selected_ped_in_the_box(found_list, select_box)\n",
    "        cv2.putText(new_image, f'Number of pedestrain within region is {len(selected_found_list)}', (10, 990), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)\n",
    "    next_output_images.append(new_image)\n",
    "    new_image = cv2.resize(new_image,dsize=(int(org_w/scale_size),int(org_h/scale_size)),fx=1,fy=1,interpolation=cv2.INTER_LINEAR)\n",
    "    PIL_image = Image.fromarray(new_image)\n",
    "    photo = ImageTk.PhotoImage(PIL_image)\n",
    "\n",
    "    image_label.configure(image=photo)\n",
    "    image_label.image = photo\n",
    "\n",
    "    my_window.update_idletasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b4f7c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial HOG\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccf3330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter image path here\n",
    "file_path = \"step_images/train/STEP-ICCV21-02/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58e039aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main - Open the Tkinter GUI\n",
    "sorted_images = sorted_image_path(file_path)\n",
    "play_output_images = []\n",
    "next_output_images = []\n",
    "img_cur_idx = 0\n",
    "total_ped_dict = {}\n",
    "ini_image = load_image()\n",
    "scale_size = 2\n",
    "org_h, org_w, l = ini_image.shape\n",
    "ini_image = cv2.resize(ini_image,dsize=(int(org_w/scale_size),int(org_h/scale_size)),fx=1,fy=1,interpolation=cv2.INTER_LINEAR)\n",
    "image_shape = ini_image.shape\n",
    "my_window = Tk()\n",
    "\n",
    "my_window.title(\"Track Pedestrians\")\n",
    "my_window.geometry(f'{image_shape[1]+200}x{image_shape[0]}')\n",
    "\n",
    "ini_PIL_image = Image.fromarray(ini_image)\n",
    "ini_photo = ImageTk.PhotoImage(image=ini_PIL_image)\n",
    "\n",
    "stop = False\n",
    "selected_cell = 0\n",
    "total_distance = 0\n",
    "frame = 0\n",
    "select = False\n",
    "selected_cell_sequence = []\n",
    "pre_center_list = []\n",
    "line_list = []\n",
    "total_num_ped = 0\n",
    "\n",
    "total_ped_list = []\n",
    "\n",
    "topx, topy, botx, boty = 0, 0, 0, 0\n",
    "rect_id = None\n",
    "\n",
    "image_label = Label(my_window, image=ini_photo)\n",
    "image_label.place(x=0, y=0)\n",
    "image_label.bind('<Button-1>', get_mouse_posn)\n",
    "image_label.bind('<B1-Motion>', update_sel_rect)\n",
    "Button(my_window, text='next image', command=next_image, font=(\"Arial\", 20)).place(x=image_shape[1]+30, y=340)\n",
    "Button(my_window, text='play video', command=play_video, font=(\"Arial\", 20)).place(x=image_shape[1]+30, y=410)\n",
    "my_window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0f582b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_video(images, video_name):\n",
    "    assert images, \"the list is empty\"\n",
    "    h, w, l = images[0].shape\n",
    "    size = (w, h)\n",
    "    video_output = cv2.VideoWriter(video_name,cv2.VideoWriter_fourcc(*'DIVX'), 4, size)\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        video_output.write(img)\n",
    "    video_output.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97a66169",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "the list is empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Export play video button results as vide0\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Note: if it didn't run the play video button it will return a AssertionError\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mconstruct_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplay_output_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrain Set - Track Pedestrians - play video.avi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mconstruct_video\u001b[0;34m(images, video_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstruct_video\u001b[39m(images, video_name):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m images, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe list is empty\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m     h, w, l \u001b[38;5;241m=\u001b[39m images[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      4\u001b[0m     size \u001b[38;5;241m=\u001b[39m (w, h)\n",
      "\u001b[0;31mAssertionError\u001b[0m: the list is empty"
     ]
    }
   ],
   "source": [
    "# Export play video button results as vide0\n",
    "# Note: if it didn't run the play video button it will return a AssertionError\n",
    "construct_video(play_output_images, \"Train Set - Track Pedestrians - play video.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1295a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export next video button results as vide0\n",
    "# Note: if it didn't run the next video button it will return a AssertionError\n",
    "construct_video(next_output_images, \"Train Set - Track Pedestrians - next video.avi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
